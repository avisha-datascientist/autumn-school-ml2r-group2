{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3 0.3 0.6 ... 0.4 0.1 0.6]\n",
      " [0.1 0.2 0.2 ... 0.3 0.6 0.3]\n",
      " [0.3 0.8 0.3 ... 0.1 0.1 0.3]\n",
      " ...\n",
      " [0.1 0.8 0.1 ... 0.1 0.6 0.2]\n",
      " [0.3 0.1 0.3 ... 0.9 0.2 0.9]\n",
      " [0.2 0.1 0.3 ... 0.3 0.1 0.2]]\n",
      "[[0.3 0.3 0.  ... 0.9 0.4 0.7]\n",
      " [0.1 0.2 0.  ... 0.4 0.6 0.7]\n",
      " [0.3 0.8 0.  ... 0.1 0.7 0.7]\n",
      " ...\n",
      " [0.1 0.8 0.  ... 0.4 0.8 0.7]\n",
      " [0.3 0.1 0.  ... 0.8 0.1 0.7]\n",
      " [0.2 0.1 0.  ... 0.9 0.7 0.7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_input = np.load('D:/Dataset_1/input.npy', allow_pickle=True) \n",
    "dataset_output = np.load('D:/Dataset_1/output.npy', allow_pickle=True)\n",
    "\n",
    "dataset_input = dataset_input.astype('float32') / 10.\n",
    "dataset_output  = dataset_output.astype('float32') / 10.\n",
    "print(dataset_input)\n",
    "print(dataset_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 200)\n",
      "(1600, 500)\n",
      "(400, 200)\n",
      "(400, 500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_input, dataset_output, test_size=0.2, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def create_dense_ae():\n",
    "    # Dimension of coded representation\n",
    "    encoding_dim = 200\n",
    "\n",
    "    # Encoder\n",
    "    # Input placeholder\n",
    "    input_element = Input(shape=200) # 1, 200, 1 - dimensions of strings, cloumns and filters of one sample element\n",
    "    # Representation coded with fully connected layer\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_element)\n",
    "    \n",
    "    # Decoder\n",
    "    # Representation uncoded with another fully connected layer\n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    decoded = Dense(1*500, activation='sigmoid')(input_encoded)\n",
    "\n",
    "    # Model(input_layer, output_layer)\n",
    "    # Model(model_1, model_2)\n",
    "    encoder = Model(input_element, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_element, decoder(encoder(input_element)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder = create_dense_ae()\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 500)               100500    \n",
      "=================================================================\n",
      "Total params: 140,700\n",
      "Trainable params: 140,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.2 0.  0.  0.  0.5 0.1 0.1 0.  0.  0.5 0.3 0.  0.2 0.  0.1 0.4 0.5\n",
      " 0.2 0.  0.3 0.5 0.6 0.  0.  0.1 0.4 0.9 0.  0.  0.1 0.1 0.6 0.5 0.  0.1\n",
      " 0.1 0.9 0.5 0.  0.1 0.2 0.  0.6 0.  0.1 0.2 0.1 0.6 0.  0.1 0.2 0.  0.8\n",
      " 0.  0.1 0.2 0.1 0.8 0.  0.3 0.3 0.2 0.6 0.  0.4 0.3 0.5 0.6 0.  0.4 0.1\n",
      " 0.2 0.9 0.  0.3 0.1 0.6 0.9 0.  0.6 0.2 0.  0.  0.1 0.5 0.6 0.  0.3 0.1\n",
      " 0.2 0.1 0.6 0.  0.1 0.2 0.7 0.6 0.2 0.1 0.7 0.1 0.  0.9 0.1 0.1 0.1 0.7\n",
      " 0.9 0.1 0.1 0.1 0.8 0.  0.1 0.1 0.1 0.9 0.  0.1 0.1 0.1 0.8 0.1 0.1 0.1\n",
      " 0.6 0.8 0.3 0.1 0.1 0.1 0.9 0.1 0.1 0.1 0.8 0.9 0.2 0.1 0.1 0.4 0.  0.\n",
      " 0.2 0.1 0.3 0.  0.4 0.2 0.1 0.1 0.1 0.  0.2 0.1 0.5 0.1 0.2 0.2 0.1 0.1\n",
      " 0.  0.7 0.2 0.1 0.1 0.  0.9 0.2 0.1 0.1 0.1 0.7 0.2 0.1 0.1 0.1 0.8 0.2\n",
      " 0.1 0.4 0.2 0.  0.2 0.1 0.1 0.2 0.5 0.2 0.6 0.3 0.4 0.  0.2 0.4 0.2 0.4\n",
      " 0.3 0.2 0.7 0.3 0.2 0.6 0.2 0.7 0.1 0.2 0.9 0.2 0.1 0.2 0.9 0.6 0.2 0.1\n",
      " 0.1 0.9 0.8 0.2 0.4 0.1 0.  0.  0.3 0.4 0.6 0.  0.1 0.3 0.2 0.1 0.4 0.\n",
      " 0.3 0.3 0.4 0.4 0.3 0.3 0.4 0.1 0.  0.7 0.3 0.4 0.2 0.  0.8 0.3 0.3 0.1\n",
      " 0.4 0.7 0.3 0.3 0.2 0.4 0.8 0.3 0.2 0.6 0.7 0.  0.3 0.2 0.1 0.7 0.6 0.3\n",
      " 0.1 0.3 0.9 0.  0.3 0.1 0.4 0.9 0.3 0.3 0.2 0.1 0.7 0.7 0.3 0.2 0.2 0.7\n",
      " 0.8 0.3 0.1 0.2 0.9 0.7 0.3 0.1 0.1 0.9 0.9 0.3 0.1 0.7 0.  0.  0.4 0.1\n",
      " 0.3 0.  0.7 0.4 0.1 0.3 0.1 0.  0.4 0.1 0.2 0.1 0.3 0.4 0.7 0.4 0.3 0.\n",
      " 0.4 0.7 0.1 0.3 0.4 0.4 0.6 0.4 0.1 0.5 0.4 0.6 0.1 0.1 0.9 0.4 0.3 0.3\n",
      " 0.7 0.5 0.4 0.3 0.2 0.7 0.8 0.4 0.1 0.1 0.  0.  0.5 0.9 0.1 0.1 0.  0.5\n",
      " 0.4 0.8 0.  0.1 0.5 0.4 0.8 0.5 0.1 0.5 0.8 0.1 0.  0.9 0.5 0.1 0.1 0.8\n",
      " 0.9 0.5 0.1 0.5 0.9 0.1 0.5 0.1 0.4 0.9 0.6 0.5 0.1 0.1 0.6 0.9 0.6 0.1\n",
      " 0.1 0.9 0.9 0.6 0.1 0.2 0.  0.  0.6 0.1 0.4 0.  0.2 0.6 0.5 0.4 0.1 0.\n",
      " 0.6 0.5 0.1 0.1 0.5 0.6 0.1 0.1 0.  0.6 0.6 0.2 0.2 0.  0.8 0.6 0.4 0.3\n",
      " 0.2 0.6 0.6 0.4 0.1 0.2 0.9 0.6 0.2 0.6 0.6 0.  0.6 0.2 0.3 0.6 0.6 0.6\n",
      " 0.1 0.2 0.8 0.  0.6 0.2 0.7 0.8 0.2 0.6 0.8 0.3 0.  0.  0.7 0.9 0.3 0.\n",
      " 0.3 0.7 0.1 0.3 0.9 0.  0.7 0.1 0.2 0.9 0.4 0.7 0.2 0.1 0.  0.6 0.7 0.2\n",
      " 0.3 0.  0.7 0.7 0.7 0.2 0.2 0.6 0.7 0.8 0.1 0.2 0.8 0.7]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 11098.9697 - val_loss: 11145.3867\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11181.9941 - val_loss: 11160.4648\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11178.2305 - val_loss: 11145.0635\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11160.2051 - val_loss: 11124.9775\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11139.3350 - val_loss: 11103.6016\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11117.8584 - val_loss: 11082.0723\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11096.2197 - val_loss: 11060.3496\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11074.4072 - val_loss: 11038.4678\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11052.4502 - val_loss: 11016.4570\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11030.3516 - val_loss: 10994.2891\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11008.0928 - val_loss: 10971.9600\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10985.6699 - val_loss: 10949.4629\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10963.0791 - val_loss: 10926.7998\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 10940.3174 - val_loss: 10903.9639\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 10917.3838 - val_loss: 10880.9551\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 10894.2783 - val_loss: 10857.7734\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10870.9971 - val_loss: 10834.4150\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10847.5391 - val_loss: 10810.8828\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10823.9062 - val_loss: 10787.1729\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10800.0928 - val_loss: 10763.2842\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10776.1025 - val_loss: 10739.2178\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10751.9346 - val_loss: 10714.9727\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10727.5859 - val_loss: 10690.5488\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10703.0596 - val_loss: 10665.9473\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10678.3535 - val_loss: 10641.1660\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10653.4688 - val_loss: 10616.2051\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10628.4023 - val_loss: 10591.0654\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10603.1592 - val_loss: 10565.7451\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10577.7334 - val_loss: 10540.2471\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10552.1299 - val_loss: 10514.5703\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10526.3486 - val_loss: 10488.7148\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10500.3848 - val_loss: 10462.6797\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10474.2461 - val_loss: 10436.4668\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10447.9258 - val_loss: 10410.0752\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10421.4277 - val_loss: 10383.5049\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10394.7529 - val_loss: 10356.7578\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10367.8984 - val_loss: 10329.8330\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10340.8672 - val_loss: 10302.7324\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10313.6582 - val_loss: 10275.4541\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10286.2725 - val_loss: 10247.9990\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10258.7119 - val_loss: 10220.3691\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10230.9727 - val_loss: 10192.5625\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10203.0596 - val_loss: 10164.5811\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10174.9707 - val_loss: 10136.4258\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10146.7070 - val_loss: 10108.0967\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10118.2715 - val_loss: 10079.5928\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10089.6592 - val_loss: 10050.9160\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10060.8740 - val_loss: 10022.0664\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10032.0527 - val_loss: 9993.5137\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10003.6641 - val_loss: 9965.1836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bd9b989280>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, y_train,\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=False,\n",
    "                validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.01432377 0.02253425 0.         1.\n",
      " 1.         1.         1.         0.         1.         1.\n",
      " 1.         1.         0.         1.         1.         1.\n",
      " 1.         0.         1.         1.         1.         1.\n",
      " 0.         1.         1.         1.         1.         0.\n",
      " 1.         1.         1.         1.         0.         1.\n",
      " 1.         1.         1.         0.         1.         1.\n",
      " 1.         1.         0.00440159 1.         1.         1.\n",
      " 1.         0.00493029 1.         1.         1.         1.\n",
      " 0.01982111 1.         1.         1.         1.         0.02341294\n",
      " 1.         1.         1.         1.         0.02294454 1.\n",
      " 1.         1.         1.         0.02377334 1.         1.\n",
      " 1.         1.         0.05179331 1.         1.         1.\n",
      " 1.         0.05493581 1.         1.         1.         1.\n",
      " 0.08868879 1.         1.         1.         1.         0.09992495\n",
      " 1.         1.         1.         1.         0.1057457  1.\n",
      " 1.         1.         1.         0.08117437 1.         1.\n",
      " 1.         1.         0.         1.         1.         1.\n",
      " 1.         0.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.09331954 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "[0.1 0.2 0.  0.  0.  0.5 0.1 0.1 0.  0.  0.5 0.3 0.  0.2 0.  0.1 0.4 0.5\n",
      " 0.2 0.  0.3 0.5 0.6 0.  0.  0.1 0.4 0.9 0.  0.  0.1 0.1 0.6 0.5 0.  0.1\n",
      " 0.1 0.9 0.5 0.  0.1 0.2 0.  0.6 0.  0.1 0.2 0.1 0.6 0.  0.1 0.2 0.  0.8\n",
      " 0.  0.1 0.2 0.1 0.8 0.  0.3 0.3 0.2 0.6 0.  0.4 0.3 0.5 0.6 0.  0.4 0.1\n",
      " 0.2 0.9 0.  0.3 0.1 0.6 0.9 0.  0.6 0.2 0.  0.  0.1 0.5 0.6 0.  0.3 0.1\n",
      " 0.2 0.1 0.6 0.  0.1 0.2 0.7 0.6 0.2 0.1 0.7 0.1 0.  0.9 0.1 0.1 0.1 0.7\n",
      " 0.9 0.1 0.1 0.1 0.8 0.  0.1 0.1 0.1 0.9 0.  0.1 0.1 0.1 0.8 0.1 0.1 0.1\n",
      " 0.6 0.8 0.3 0.1 0.1 0.1 0.9 0.1 0.1 0.1 0.8 0.9 0.2 0.1 0.1 0.4 0.  0.\n",
      " 0.2 0.1 0.3 0.  0.4 0.2 0.1 0.1 0.1 0.  0.2 0.1 0.5 0.1 0.2 0.2 0.1 0.1\n",
      " 0.  0.7 0.2 0.1 0.1 0.  0.9 0.2 0.1 0.1 0.1 0.7 0.2 0.1 0.1 0.1 0.8 0.2\n",
      " 0.1 0.4 0.2 0.  0.2 0.1 0.1 0.2 0.5 0.2 0.6 0.3 0.4 0.  0.2 0.4 0.2 0.4\n",
      " 0.3 0.2 0.7 0.3 0.2 0.6 0.2 0.7 0.1 0.2 0.9 0.2 0.1 0.2 0.9 0.6 0.2 0.1\n",
      " 0.1 0.9 0.8 0.2 0.4 0.1 0.  0.  0.3 0.4 0.6 0.  0.1 0.3 0.2 0.1 0.4 0.\n",
      " 0.3 0.3 0.4 0.4 0.3 0.3 0.4 0.1 0.  0.7 0.3 0.4 0.2 0.  0.8 0.3 0.3 0.1\n",
      " 0.4 0.7 0.3 0.3 0.2 0.4 0.8 0.3 0.2 0.6 0.7 0.  0.3 0.2 0.1 0.7 0.6 0.3\n",
      " 0.1 0.3 0.9 0.  0.3 0.1 0.4 0.9 0.3 0.3 0.2 0.1 0.7 0.7 0.3 0.2 0.2 0.7\n",
      " 0.8 0.3 0.1 0.2 0.9 0.7 0.3 0.1 0.1 0.9 0.9 0.3 0.1 0.7 0.  0.  0.4 0.1\n",
      " 0.3 0.  0.7 0.4 0.1 0.3 0.1 0.  0.4 0.1 0.2 0.1 0.3 0.4 0.7 0.4 0.3 0.\n",
      " 0.4 0.7 0.1 0.3 0.4 0.4 0.6 0.4 0.1 0.5 0.4 0.6 0.1 0.1 0.9 0.4 0.3 0.3\n",
      " 0.7 0.5 0.4 0.3 0.2 0.7 0.8 0.4 0.1 0.1 0.  0.  0.5 0.9 0.1 0.1 0.  0.5\n",
      " 0.4 0.8 0.  0.1 0.5 0.4 0.8 0.5 0.1 0.5 0.8 0.1 0.  0.9 0.5 0.1 0.1 0.8\n",
      " 0.9 0.5 0.1 0.5 0.9 0.1 0.5 0.1 0.4 0.9 0.6 0.5 0.1 0.1 0.6 0.9 0.6 0.1\n",
      " 0.1 0.9 0.9 0.6 0.1 0.2 0.  0.  0.6 0.1 0.4 0.  0.2 0.6 0.5 0.4 0.1 0.\n",
      " 0.6 0.5 0.1 0.1 0.5 0.6 0.1 0.1 0.  0.6 0.6 0.2 0.2 0.  0.8 0.6 0.4 0.3\n",
      " 0.2 0.6 0.6 0.4 0.1 0.2 0.9 0.6 0.2 0.6 0.6 0.  0.6 0.2 0.3 0.6 0.6 0.6\n",
      " 0.1 0.2 0.8 0.  0.6 0.2 0.7 0.8 0.2 0.6 0.8 0.3 0.  0.  0.7 0.9 0.3 0.\n",
      " 0.3 0.7 0.1 0.3 0.9 0.  0.7 0.1 0.2 0.9 0.4 0.7 0.2 0.1 0.  0.6 0.7 0.2\n",
      " 0.3 0.  0.7 0.7 0.7 0.2 0.2 0.6 0.7 0.8 0.1 0.2 0.8 0.7]\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "#imgs = X_test[:n]\n",
    "imgs = X_train[:n]\n",
    "encoded = encoder.predict(imgs, batch_size=n)\n",
    "\n",
    "#decoded = np.round(decoder.predict(encoded, batch_size=n), 0)\n",
    "decoded = decoder.predict(encoded, batch_size=n)\n",
    "print(decoded[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_dense_ae():\n",
    "    # Размерность кодированного представления\n",
    "    encoding_dim = 200\n",
    "\n",
    "    # Энкодер\n",
    "    input_img = Input(shape=200)\n",
    "    x = Dense(encoding_dim*1, activation='relu')(input_img)\n",
    "    x = Dense(encoding_dim*2, activation='relu')(x)\n",
    "    encoded = Dense(encoding_dim, activation='linear')(x)\n",
    "    \n",
    "    # Декодер\n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    x = Dense(encoding_dim*2, activation='relu')(input_encoded)\n",
    "    x = Dense(encoding_dim*3, activation='relu')(x)\n",
    "    decoded = Dense(1*500, activation='sigmoid')(x)\n",
    "    \n",
    "    # Модели\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "d_encoder, d_decoder, d_autoencoder = create_deep_dense_ae()\n",
    "d_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 200)               200800    \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 500)               621500    \n",
      "=================================================================\n",
      "Total params: 822,300\n",
      "Trainable params: 822,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.6183 - val_loss: 0.5865\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5845 - val_loss: 0.5825\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5826 - val_loss: 0.5815\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5820 - val_loss: 0.5811\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5815 - val_loss: 0.5806\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5806 - val_loss: 0.5794\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5790 - val_loss: 0.5777\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5771 - val_loss: 0.5764\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5751 - val_loss: 0.5747\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5728 - val_loss: 0.5727\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5702 - val_loss: 0.5709\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5681 - val_loss: 0.5704\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5661 - val_loss: 0.5684\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5643 - val_loss: 0.5678\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5627 - val_loss: 0.5664\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5607 - val_loss: 0.5664\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5590 - val_loss: 0.5651\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5571 - val_loss: 0.5643\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5553 - val_loss: 0.5633\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5535 - val_loss: 0.5633\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5519 - val_loss: 0.5633\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5509 - val_loss: 0.5628\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5500 - val_loss: 0.5626\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5479 - val_loss: 0.5620\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5462 - val_loss: 0.5622\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5443 - val_loss: 0.5624\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5426 - val_loss: 0.5614\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5412 - val_loss: 0.5619\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5406 - val_loss: 0.5664\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5404 - val_loss: 0.5638\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5383 - val_loss: 0.5618\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5355 - val_loss: 0.5629\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5336 - val_loss: 0.5636\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5323 - val_loss: 0.5641\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5317 - val_loss: 0.5651\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5308 - val_loss: 0.5647\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5295 - val_loss: 0.5662\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5285 - val_loss: 0.5674\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5274 - val_loss: 0.5684\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5262 - val_loss: 0.5688\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5261 - val_loss: 0.5687\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5244 - val_loss: 0.5699\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5240 - val_loss: 0.5673\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5222 - val_loss: 0.5680\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5193 - val_loss: 0.5689\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5180 - val_loss: 0.5689\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5171 - val_loss: 0.5704\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5163 - val_loss: 0.5715\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5153 - val_loss: 0.5727\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5155 - val_loss: 0.5739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bd9bf91700>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_autoencoder.fit(X_train, y_train,\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=False,\n",
    "                validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.01432377 0.02253425 0.         1.\n",
      " 1.         1.         1.         0.         1.         1.\n",
      " 1.         1.         0.         1.         1.         1.\n",
      " 1.         0.         1.         1.         1.         1.\n",
      " 0.         1.         1.         1.         1.         0.\n",
      " 1.         1.         1.         1.         0.         1.\n",
      " 1.         1.         1.         0.         1.         1.\n",
      " 1.         1.         0.00440159 1.         1.         1.\n",
      " 1.         0.00493029 1.         1.         1.         1.\n",
      " 0.01982111 1.         1.         1.         1.         0.02341294\n",
      " 1.         1.         1.         1.         0.02294454 1.\n",
      " 1.         1.         1.         0.02377334 1.         1.\n",
      " 1.         1.         0.05179331 1.         1.         1.\n",
      " 1.         0.05493581 1.         1.         1.         1.\n",
      " 0.08868879 1.         1.         1.         1.         0.09992495\n",
      " 1.         1.         1.         1.         0.1057457  1.\n",
      " 1.         1.         1.         0.08117437 1.         1.\n",
      " 1.         1.         0.         1.         1.         1.\n",
      " 1.         0.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.09331954 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "[0.1 0.2 0.  0.  0.  0.5 0.1 0.1 0.  0.  0.5 0.3 0.  0.2 0.  0.1 0.4 0.5\n",
      " 0.2 0.  0.3 0.5 0.6 0.  0.  0.1 0.4 0.9 0.  0.  0.1 0.1 0.6 0.5 0.  0.1\n",
      " 0.1 0.9 0.5 0.  0.1 0.2 0.  0.6 0.  0.1 0.2 0.1 0.6 0.  0.1 0.2 0.  0.8\n",
      " 0.  0.1 0.2 0.1 0.8 0.  0.3 0.3 0.2 0.6 0.  0.4 0.3 0.5 0.6 0.  0.4 0.1\n",
      " 0.2 0.9 0.  0.3 0.1 0.6 0.9 0.  0.6 0.2 0.  0.  0.1 0.5 0.6 0.  0.3 0.1\n",
      " 0.2 0.1 0.6 0.  0.1 0.2 0.7 0.6 0.2 0.1 0.7 0.1 0.  0.9 0.1 0.1 0.1 0.7\n",
      " 0.9 0.1 0.1 0.1 0.8 0.  0.1 0.1 0.1 0.9 0.  0.1 0.1 0.1 0.8 0.1 0.1 0.1\n",
      " 0.6 0.8 0.3 0.1 0.1 0.1 0.9 0.1 0.1 0.1 0.8 0.9 0.2 0.1 0.1 0.4 0.  0.\n",
      " 0.2 0.1 0.3 0.  0.4 0.2 0.1 0.1 0.1 0.  0.2 0.1 0.5 0.1 0.2 0.2 0.1 0.1\n",
      " 0.  0.7 0.2 0.1 0.1 0.  0.9 0.2 0.1 0.1 0.1 0.7 0.2 0.1 0.1 0.1 0.8 0.2\n",
      " 0.1 0.4 0.2 0.  0.2 0.1 0.1 0.2 0.5 0.2 0.6 0.3 0.4 0.  0.2 0.4 0.2 0.4\n",
      " 0.3 0.2 0.7 0.3 0.2 0.6 0.2 0.7 0.1 0.2 0.9 0.2 0.1 0.2 0.9 0.6 0.2 0.1\n",
      " 0.1 0.9 0.8 0.2 0.4 0.1 0.  0.  0.3 0.4 0.6 0.  0.1 0.3 0.2 0.1 0.4 0.\n",
      " 0.3 0.3 0.4 0.4 0.3 0.3 0.4 0.1 0.  0.7 0.3 0.4 0.2 0.  0.8 0.3 0.3 0.1\n",
      " 0.4 0.7 0.3 0.3 0.2 0.4 0.8 0.3 0.2 0.6 0.7 0.  0.3 0.2 0.1 0.7 0.6 0.3\n",
      " 0.1 0.3 0.9 0.  0.3 0.1 0.4 0.9 0.3 0.3 0.2 0.1 0.7 0.7 0.3 0.2 0.2 0.7\n",
      " 0.8 0.3 0.1 0.2 0.9 0.7 0.3 0.1 0.1 0.9 0.9 0.3 0.1 0.7 0.  0.  0.4 0.1\n",
      " 0.3 0.  0.7 0.4 0.1 0.3 0.1 0.  0.4 0.1 0.2 0.1 0.3 0.4 0.7 0.4 0.3 0.\n",
      " 0.4 0.7 0.1 0.3 0.4 0.4 0.6 0.4 0.1 0.5 0.4 0.6 0.1 0.1 0.9 0.4 0.3 0.3\n",
      " 0.7 0.5 0.4 0.3 0.2 0.7 0.8 0.4 0.1 0.1 0.  0.  0.5 0.9 0.1 0.1 0.  0.5\n",
      " 0.4 0.8 0.  0.1 0.5 0.4 0.8 0.5 0.1 0.5 0.8 0.1 0.  0.9 0.5 0.1 0.1 0.8\n",
      " 0.9 0.5 0.1 0.5 0.9 0.1 0.5 0.1 0.4 0.9 0.6 0.5 0.1 0.1 0.6 0.9 0.6 0.1\n",
      " 0.1 0.9 0.9 0.6 0.1 0.2 0.  0.  0.6 0.1 0.4 0.  0.2 0.6 0.5 0.4 0.1 0.\n",
      " 0.6 0.5 0.1 0.1 0.5 0.6 0.1 0.1 0.  0.6 0.6 0.2 0.2 0.  0.8 0.6 0.4 0.3\n",
      " 0.2 0.6 0.6 0.4 0.1 0.2 0.9 0.6 0.2 0.6 0.6 0.  0.6 0.2 0.3 0.6 0.6 0.6\n",
      " 0.1 0.2 0.8 0.  0.6 0.2 0.7 0.8 0.2 0.6 0.8 0.3 0.  0.  0.7 0.9 0.3 0.\n",
      " 0.3 0.7 0.1 0.3 0.9 0.  0.7 0.1 0.2 0.9 0.4 0.7 0.2 0.1 0.  0.6 0.7 0.2\n",
      " 0.3 0.  0.7 0.7 0.7 0.2 0.2 0.6 0.7 0.8 0.1 0.2 0.8 0.7]\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "#imgs = X_test[:n]\n",
    "imgs = X_train[:n]\n",
    "encoded = encoder.predict(imgs, batch_size=n)\n",
    "\n",
    "#decoded = np.round(decoder.predict(encoded, batch_size=n), 0)\n",
    "decoded = decoder.predict(encoded, batch_size=n)\n",
    "print(decoded[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
